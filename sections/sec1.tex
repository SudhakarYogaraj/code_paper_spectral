\section{Polynomial approximation in weighted space}
We will start by presenting the construction of these polynomials. In 1
dimension, it is well-known that the polynomials
\begin{equation}
    H_n(s; \sigma) = \frac{(-\sigma)^n}{\sqrt{n!}}
    \exp\left({\frac{s^2}{2\sigma^2}}\right)\frac{\mathrm d ^n}{\mathrm d
    s^n}\left(\exp{\left(\frac{-s^2}{2\sigma^2}\right)}\right)
    \label{Hermite polynomials in 1 dimension}
\end{equation}
are orthonormal for the inner product defined by:
$$ \left \langle u, v \right \rangle_{g_{\sigma^2}} = \int_{\real} u \, v \, g_{\sigma^2} \, ds. $$
where $g_{\sigma^2}$ is the gaussian density of mean 0 and variance $\sigma^2$.
In addition, they form a complete orthonormal basis of the space $L^2(\real,
g_{\sigma^2})$. In the multidimensional case, it is also possible to obtain
polynomials that have these properties.
\begin{lemma}[Complete orthonormal basis of $L^2(\real^n, \rho)$]
   Suppose that $\Sigma \in \real^{n\times n}$ is symmetric positive definite,
   and let $\gaussian{\Sigma}$ be the gaussian density of mean $0$ and covariance
   matrix $\Sigma$. Let also $D$ and $Q$ be diagonal and orthogonal matrices
   such that $D = Q^T \Sigma Q$, and note $\sigma_k$ the $k$-th element on the
   diagonal of $D$. Then the polynomials defined by
    \begin{equation}
        \hermite H_{\alpha}(y)\,=\, \hermite G_{\alpha} (Q^T y) \quad \text{with}
        \quad \hermite G_\alpha(z)={\prod}_{k\,=\,1}^n H_{\alpha_k}(z_k; \sigma_k).
        \label{eq: Definition of modified Hermite polynomials}
    \end{equation}
    form a complete orthonormal basis of $L^2(\real^n, \gaussian{\Sigma})$.
\end{lemma}
\iflong \begin{proof}
    The proof of the completeness can be found in \cite{andrews2000special}.
    We check the orthonormality
    \begin{align*}
    \int_{\real^n} \hermite H_\alpha \, \hermite H_\beta \, \gaussian{\Sigma}
    \, dy &= \frac{1}{\sqrt{(2\pi)^k| \Sigma|}}\int_{\real^n}\hermite G_\alpha
    (Q^T y) \,\hermite G_\beta (Q^T y) \,
    \exp\left(-\frac{1}{2}(Q^Ty)^T D^{-1} (Q^Ty) \right) \, dy  \\
    &=  \frac{1}{\sqrt{(2\pi)^k| D|}}\int_{\real^n}\hermite G_\alpha (z)
    \,\hermite G_\beta (z) \,  \exp\left(-\frac{1}{2}z^T D^{-1}z \right) \, dz
    \\ &= \prod_{k=1}^n \int_{\real} H_{\alpha_k}(z_k,\sigma_k) \,
    H_{\beta_k}(z_k; \sigma_k) \, g_{\sigma_k^2} \, dz_k = \prod_{k=1}^n
    \delta_{\alpha_k,\beta_k}.
    \end{align*}
\end{proof} \fi
Additionally, the polynomials associated with $\Sigma_\infty$ are the
eigenfunctions of the operator $\op L_0$, and the associated eigenfunctions can
be calculated explicitely.
\begin{lemma}[Eigenfunctions of $\op L_0$]
    The polynomials defined in \eqref{eq: Definition of modified Hermite
    polynomials} are (\red{the?}) eigenfunctions of the operator $\op L_0$, and
    the eigenvalue associated to $\hermite H_{\alpha}$ is equal to
    $\mu_{\alpha}=\sum_{i=k}^n \alpha_i \lambda_A^k$, where $\lambda_A^k$ is the $k$-th
    element on the diagonal of $D_A$.
\end{lemma}

\iflong \begin{proof}
    We prove this in two steps. First, we show that $\hermite H_\alpha$ is an
    eigenfunction of $\op L_0$ if and only if $\hermite G_\alpha$ is an
    eigenfunction of a simpler operator, which we prove in the second step. Let
    $\op Q: L^2(\real^n, \rho) \rightarrow L^2(\real^n, \gaussian{D_\infty})$ be the
    rotation operator defined by $\op Q f (z) = f(Qz)$, and let $\op D_0 = \op Q \,
    \op L_0 \, \op Q^{-1}$. With these notations, $\op Q \, \hermite H_\alpha =
    \hermite G_\alpha$ and it follows that $\op L_0 \, \hermite H_\alpha = \lambda_\alpha  \hermite
    H_\alpha$ if and only if $\op D_0 \, \hermite G_\alpha \,=\, \lambda_\alpha
    \hermite G_\alpha$, where the polynomials $\hermite G_{\alpha}$ are as
    defined in \eqref{eq: Definition of modified Hermite polynomials}.
    Consequently, it is sufficient to show that the polynomials $\hermite
    G_\alpha$ are eigenfunctions of $\op D_0$, the expression of which is simpler
    than that of $\op L_0$:
    $$ \op D_0 \,=\, D_A z \cdot \nabla \,+\, \frac{1}{2}D_{\Sigma}:\nabla\nabla. $$
    This can be done by recursion. Suppose we showed that the polynomials $\hermite
    G_{\gamma}$ are eigenfunctions of $\op D_0$ for $\gamma \leq \beta$. We
    will show that $\hermite G_{\alpha}$ is also an eigenfunction if
    $|{\alpha}-{\beta}| = 1$. To this purpose, we define the space $P_{\alpha}$ of
    all polynomials that can be written as $p(z) \,=\, {\sum}_{{\gamma}\, {\leq}
    \,{\alpha}} c_{\gamma}\, z^{\gamma}$. From the expression of $\op D_0$,
    notice that $\op D_0(P_{\alpha}) \,{\subset}\,P_{\alpha}$, which implies that
    $$
        \op D_0 \, \hermite G_{\alpha}\,=\, \sum_{\gamma\, \leq \, \alpha} \langle \op
        D_0\,\hermite G_{\alpha},\, \hermite G_{\beta}\rangle_{\gaussian{D_{\infty}}}\, \hermite
        G_{\beta},
    $$
    since by the previous lemma the polynomials $\hermite G_{\alpha}$ form a
    complete orthonormal basis of $L^2(\real^n, g_{D_\infty})$.  Using the
    induction hypothesis, the symmetry of the operator, and the orthonormality
    of the Hermite polynomials gives:
    \begin{equation*}
        \begin{aligned}
            \op D_0 \, \hermite G_{\alpha}\,&=\, \sum_{\gamma\, \leq \, \alpha} \langle \hermite
            G_{\alpha},\, \op D_0 \hermite G_{\beta}\rangle_{\gaussian{D_\infty}}\, \hermite G_{\beta} \\
            \,&=\, \sum_{\gamma\, \leq \beta} \mu_{\beta}\, \langle \hermite G_{\alpha}, \,
            \hermite G_{\beta}\rangle_{\gaussian{D_\infty}}\, \hermite G_{\beta}\,+\, \langle \op D_0\,\hermite
            G_{\alpha},\, \hermite G_{\alpha}\rangle_{\gaussian{D_\infty}} \, \hermite G_{\alpha}.\\
            &= \, \langle \op D_0\,\hermite
            G_{\alpha},\, \hermite G_{\alpha}\rangle_{\gaussian{D_\infty}} \, \hermite G_{\alpha}.
        \end{aligned}
    \end{equation*}
    Hence $\hermite G_\alpha$ is an eigenfunction of $\mathcal D_0$. The associated
    eigenvalue can be obtained by considering the term $z^{\alpha}$ in
    $\hermite G_{\alpha}$. We have:
    $$
    \op D_0\, z^{\alpha}\,=\,  \left(\sum^{n}_{i=1} \lambda_A^i \, z_i \, \pard{}{z_i}  \,-\,\frac12
        \,\sum^n_{i=1} \,{\beta}_i^2\, \pardd{}{z_i} \right)\, z^{\alpha} \,=\, \left(\sum^{n}_{i=1} \lambda_A^i \, \alpha_i \,
        \right)z^\alpha\,+\, \dots,
    $$
    where we omitted the terms of lower degrees.
\end{proof} \fi
From these two properties, it appears that the modified Hermite polynomials
defined in equation \eqref{eq: Definition of modified Hermite polynomials} are
well suited for our problem. Like Fourier series, these polynomials have very
good approximation properties for smooth functions. In what follows, we note
$\pi^d: L^2(\real^n, \rho) \rightarrow P(d)$ the $L^2(\real^n,\rho)$ projection
operator on the space of polynomials of degree lower or equal to $d$, where
$\rho = \gaussian{\Sigma_\infty}$ as before. The result we want to show is the
following:
\begin{proposition}[Approximation by polynomials in $L^2(\real^d, \gaussian{\Sigma})$]
    Let $\Sigma$ be a symmetric positive definite matrix, and suppose that
    $f\,:\,\mathbb R^n\,\to\,\mathbb R$ is a function of the space $H^s(\mathbb
    R^n,\,\gaussian{\Sigma})$. Then
    $$
        \|f\,-\,{\pi}^df\|_{\gaussian{\Sigma}}\, \leq \,C(n,s) \, (d+1)^{-\frac{s}{2}}\, |f|_{\gaussian{\Sigma},s},
    $$
    when $d \geq s-1$.
    \label{proposition: approx Hermite}
\end{proposition}
Before we prove this result, we will need a few results. First, notice that,
for a function $f \in L^2(\real^n, \gaussian{\Sigma})$,
\begin{align}
    \int_{\real^n} (f(y)-\pi^d f(y))^2 \,d\gaussian{\Sigma} &\,=\,
    \int_{\real^n} (f(Qz) - \pi^df(Qz))^2 \, d\gaussian{D}  \\ &\,=\,
    \int_{\real^n} (f(QD_\infty^{1/2}w) - \pi^df(QD_\infty^{1/2}w))^2 \, d\gaussian{I},
\end{align}
where $D$ and $Q$ are the matrices diagonalizing $\Sigma$ and we made the
changes of variables $z = Q^T y$ and $w = (D_\infty)^{-1/2}z$. Consequently, we
can assume that $\Sigma = I$ for the proof of \ref{proposition: approx
Hermite}. In what follows, we will drop the subscript $I$ to shorten the notations.
In addition, we will note $\hermite H_\alpha(y) = \hermite H_\alpha(y; I)$.

Next, notice that by integration by parts:
\begin{equation}
    \int_{\real^n}(\pard{u}{z_i})\, v\,d\stdgaussian \,=\,\int_{\real^n}u \, (\partial^*_{z_i} v)\,d\stdgaussian
    \label{eq: adjoint relation}
\end{equation}
for any two functions $u,v \in C^{\infty}_c$, and where we defined the operator
$\partial^*_{z_i} = -\pard{f}{z_i} \,+\,z_i \,f $. It is shown in
\cite{lorenzi2006analytical} that $\partial^*$ is in fact a bounded linear
operator from $H^1(\real^n, g)$ to $L^2(\real^n, g)$. It follows from this and
from the density of $C^\infty_c$ in $H^1(\real^n,g)$ that the above
relation remains true for any functions $u,v \in H^1(\real^n, g)$.
By differentiating equation \eqref{Hermite polynomials in 1 dimension}, and
using Leibniz rule we obtain following the well known recursion relation for
Hermite polynomials:
$$ H_{i+1}(s) \,=\, \frac{1}{\sqrt{i+1}}(s H_i - H_i'(s)),$$
and so $H_{i+1} =  \partial^*_s H_i/\sqrt{i+1}$. A similar formula holds in the
multi-dimensional case:
\begin{equation}
\hermite H_{\alpha + e_i} =  \partial^*_{z_i} \hermite H_\alpha/\sqrt{\alpha_i+1}
\label{eq: recursion Hermite in $n$ dimensions}
\end{equation}
Note that from \cref{eq: adjoint relation} and \cref{eq: recursion Hermite in
    $n$ dimensions}, the other well known recursion relation between Hermite
polynomials can be obtained:
\begin{equation}
    \partial_i \hermite H_{\beta} = \sum_{\alpha \,\geq\, 0} \ip{\hermite H_\beta}{\partial_i^* \hermite H_\alpha} = \sum_{\alpha \,\geq\, 0} \sqrt{\alpha_i+1}\ip{\hermite H_\beta}{\hermite H_{\alpha+e_i}} \hermite H_\alpha = \sqrt{\beta_i} \, \hermite H_{\beta-e_i}
\label{eq: recursion Hermite derivative}
\end{equation}
From equations \eqref{eq: adjoint relation} and \eqref{eq: recursion Hermite in
$n$ dimensions}, the following lemma can be obtained.
\begin{lemma}
    If $f\,\in\, H^s(\real^n, \, g)$, then for any multi-index $\beta\,
    \leq \,\alpha$ such that $|\beta|\, \leq \,s$, we have
    $$
        \left \langle f, \hermite H_\alpha \right \rangle_g \,=\,\sqrt{\frac
                {(\alpha-\beta)!}{\alpha!}} \left \langle D^\beta f, \hermite H_{\alpha-\beta} \right \rangle_g
    $$
    \label{proposition: coeff Hermite multidimensional}
\end{lemma}
\iflong \begin{proof}
    We prove the statement by recursion. Noting
    $\beta^{(j)}\,=\,(\beta_1,\,\beta_2,\,\dots\,,\,\beta_j,\, 0, \, \dots\,, \, 0) $, we will
    show that, for every $0\, \leq \,j\, \leq \,n$:
    $$
        \left \langle f, \hermite H_\alpha \right \rangle_g \,=\,\sqrt{\frac
                {(\alpha-\beta^{(j)})!}{\alpha!}} \left \langle D^{\beta^{(j)}} f, \hermite H_{\alpha-\beta^{(j)}} \right \rangle_g
    $$
    This equation is trivially satisfied for $j\,=\,0$. Assuming that the
    statement is true for $j\,=\,k-1\,<\,n$, we prove that it holds for

    $j\,=\,k$. Given the recursion hypothesis, it is sufficient to prove that:
    $$
        \left \langle
            D^{\beta^{(k-1)}} f, \hermite H_{\alpha-\beta^{(k-1)}} \right
        \rangle_g \,=\,\sqrt{\frac {(\alpha_k-\beta_k)!}{\alpha_k!}} \left \langle
            D^{\beta^{(k)}} f, \hermite H_{\alpha-\beta^{(k)}} \right \rangle_g
    $$
    which can be obtained by using equations \eqref{eq: adjoint relation} and \eqref{eq: recursion Hermite in
    $n$ dimensions} repeatedly.
\end{proof} \fi
We can now establish proposition \ref{proposition: approx Hermite}.
\iflong\begin{proof}[Proof of proposition \ref{proposition: approx Hermite}]
    From the remarks above, it is sufficient to consider the case $\Sigma= I$. From Parseval's equality:
    $$
        \| f\,-\, \pi^d f\|_{g}^2 \,=\,\sum_{|\alpha|\,>\,d} \langle f,\, \hermite H_{\alpha} \rangle_g^2.
    $$
    Since $d\, \geq \,s-1$, there exists for each term of the sum a multi-index
    $\beta(\alpha)$ such that $|\beta(\alpha)|\,=\,s$ and $\beta(\alpha)\, \leq \,\alpha$.
    Among all the possibilities remaining, we choose one such that
    $\sum^{n}_{i=1} \alpha_i \beta_i$ is maximized.  Using lemma
    \ref{proposition: coeff Hermite multidimensional}, we have
    $$
        \| f\,-\, \pi^df\|_{g}^2
        \,=\,\sum_{|\alpha|\,>\,d}\frac
                {(\alpha-\beta(\alpha))!}{\alpha!} \,\left\langle
            D^{\beta(\alpha)}f,\,\mathcal H_{(\alpha-\beta(\alpha))}\right\rangle_g^2
    $$
    Using the Sobolev semi-norm, the integral terms can be bounded:
    $$
        \sum_{|\alpha|\,>\,d} \left\langle D^{\beta(\alpha)}f,\,\hermite H_{(\alpha-\beta(\alpha))}\right\rangle_g^2
        \, \leq \, |f|_{g,s}^2 \,=\, \sum_{|\gamma| = s}\sum_{|\alpha| \geq 0} \left\langle D^{\gamma}f,\,\mathcal H_{\alpha}\right\rangle_g^2.
    $$
    To show that this inequality is true, one can notice that each of the
    elements in the sum in the right-hand side appears at most once in the
    summation on the left-hand side. Indeed, suppose that one of the terms in
    the sum of the left-hand side appears twice, for ${\alpha}_1$ and ${\alpha}_2$.
    Then ${\beta}({\alpha}_1) \,=\, {\beta}({\alpha}_2)$ and ${\alpha}_1 -{\beta}({\alpha}_1)
    \,=\,{\alpha}_2 - {\beta}({\alpha}_2)$, which leads to ${\alpha}_1 = {\alpha}_2$.  The previous inequality gives:
    $$
        \begin{aligned}
        \| f\,-\, \pi^d f\|_{g}^2 &\, \leq \,\max_{|\alpha|\,>\,d}\left({\frac
                {(\alpha-\beta(\alpha))!}{\alpha!}}\right) \, |f|_{g,s}^2 \\
            & \leq \, \max_{|\alpha|\,>\,d}\left(\frac{\beta(\alpha)^{\beta(\alpha)}}{\beta(\alpha)!}\,\frac
                1{\alpha^{\beta(\alpha)}}\right) |f|_{g,n}^2 \\
            & \leq (sn)^s(d+1)^{-s}|f|_{g,n}^2,
        \end{aligned}
    $$
    which proves the claim.
\end{proof} \fi
